学习笔记

# 复杂度分析

表示方法：大O表示法，T(n) = O(f(n))

常用的7种时间复杂度：

> O(1): Constant Complexity 常数复杂度
>
> O(log n): Logarithmic Complexity 对数复杂度
>
> O(n): Linear Complexity 线性时间复杂度
>
> O(n^2): N square Complexity 平⽅
>
> O(n^3): N square Complexity ⽴⽅
>
> O(2^n): Exponential Growth 指数
>
> O(n!): Factorial 阶乘

如何分析一段代码的时间复杂度：

极客时间训练营和王争老师的专栏这部分类似

时间复杂度可以简单理解为一段代码的执行次数

1. 只关注代码执行次数最多的的一段：循环，嵌套，递归等，刨去一些常数级别计算的代码。
2. 加法法则，和1类似， 总复杂度等于量级最大的那段代码的复杂度 ，如O(n^2) + O(n^3)即可以定义为O(n^3);另外如果一段代码执行了已知固定的次数，即使是1000,10000，那么它也只能算做常数，跟n的规模无关，当n无限大时就可以忽略。
3. 乘法法则，嵌套代码等于内外嵌套部分各自的复杂度相乘，比如双重循环n*(n - 1)，即算作O(n^2)
4. 特殊的时间复杂度
   1. 对数复杂度： O(logn)，一般出现在对数变化的算法上，比如二分查找，对数2增长(减少)。举个例子 

```java
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
```

    2. 指数复杂度：O(k^n)，一般出现在递归算法中，比如斐波拉契函数的递归形式。它的递归树每层是上一层的2倍，因此是O(2^N)

总结：时间复杂度越大在n越大的时候执行效率会变得非常低效。

有时候代码并不是像循环n次这样固定执行n遍的，代码里混合了其他分支语句。

最好时间复杂度

最坏时间复杂度

平均时间复杂度：需要用到一定简单的统计公式

均摊时间复杂度：一种特殊的平均时间复杂度。



# 数组

数组最大的特点是内存连续，支持随机访问，缺点是插入，删除，扩容需要额外的操作。

数组的特点和用法基本大家都很熟悉，

值得一提的是其内存连续的寻址公式以及索引为0开始的原因。

```java

a[k]_address = base_address + k * type_size
```

base_address：首地址

寻址公式也是数组的索引为什么从0开始的原因。

 但是，如果数组从 1 开始计数，那我们计算数组元素 a[k]的内存地址就会变为： 

```jav

a[k]_address = base_address + (k-1)*type_size
```

在内存中会多一次减法运算，对于数组这种底层的通用操作，需要尽量的快速高效。因此索引从0开始。

> 面试的时候，常常会问数组和链表的区别，很多人都回答说，“链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)”。实际上，这种表述是不准确的。数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。 --- 王争 《数据结构与算法之美》

## 数组相关的算法题总结

从第一周接触算法后开始，每道题都需要多想几种解法，最开始如果不知道比较优秀的解法，大多数都可以使用暴力求解先解决。

- 移动零： https://leetcode-cn.com/problems/move-zeroes/ 
  - 双指针：学习到了双指针的一种形式，慢指针保持最新的非零数需要插入的索引，快指针一直往下遍历，当遍历到非零数就插入慢指针位置，如果快指针!=慢指针，当前快指针赋值0，之后慢指针自增1，遍历完后慢指针后面的数自然全为0；
- 盛水最多的容器： https://leetcode-cn.com/problems/container-with-most-water/ 
  - 双指针：学习到了另一种双指针形式，双指针逼近，这种形式一般将指针放置到数据left和right两个地方。通过left和right两个指针互相比较，通过一定条件判断left往右移动还是right往左移动，不断比较移动后的max值，如有变化就更新，这样，当条件不满足left<right时，比较完成，得出最优解max。
- 三数之和： https://leetcode-cn.com/problems/3sum/ 
  - 双指针：另一种双指针降低时间复杂度的形式，是另一种形式的双指针逼近。暴力求解三数之和肉眼可见的三重循环O(n^3),利用双指针一般都可以降低一重时间复杂度。
    - 由于涉及到去重等操作，一般这类双指针逼近需要有序作为前提，因此用Arrays.sort默认升序排序
    - 核心思想是，遍历排序数组，遍历的数组[i]右侧作为双指针区域，根据判断条件不断逼近。
    - 在这道题的难点在于很多去重的边界条件。
  - map 存值法
    - i + j + k = 0  相当于 i + j = -k，-k作为target目标，遍历数组将每个数的负数作为key，index作为value存入map中。
    - 二重循环遍历数组，找出存在i + j的key，那么说明存在值。
    - 也需要去重判断。

# 链表

- 几种链表

  1. 单链表 它只有后继指针指向下一个节点，尾结点指向null
  2. 循环链表  一种特殊的单链表，尾结点指向首节点
  3. 双向链表 实际中更加常用的链表结构 前驱指针prev  后继指针 next

- 针对删除 插入时间复杂度为O(1)的说法

  我们通常说的链表删除插入快，时间复杂度为O(1)一般是只该动作本身，但是删除前进行的操作我们需要知道可能并非是O(1)

  以删除来说业务开发上通常有两种方式：

  - 删除某个值为XX的节点
  - 删除已知的地址引用的节点q

  此时如果只知道值，我们就需要去遍历链表，找到该值的节点，对于单链表或者双链表差别不大，时间复杂度O(n)

  但是如果是已知的地址引用，**对于单链表来说只存了后继指针**，而删除操作需要知道前驱节点，因此还是需要遍历到p ->next=q，这个操作是O(n)的

  **对于双向链表来说由于还存储了前驱指针**，尽管要多耗费一点内存，但是不用遍历，时间复杂度为**O(1)**

  同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度

  对于有序的链表来说，查询效率上双向链表也更有优势，可以从前或者往后查找，平均只需要找一半的数据。

- 数组VS链表

  除了通常的一些插入删除，查询等不同的时间复杂度外，数组由于内存连续可以借助cpu的缓存机制，预读数组中的数据，对cpu缓存更友好。

  数组的缺点是大小固定，扩容需要拷贝原数组，如果数组非常大就会很耗时，并且申请的扩容大小没有连续的内存有这么大则会OOM。

  链表则是每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍，频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，java中则是频繁的GC。

- 了解到链表遍历的方式：

```java
while(ListNode != null){
	listNode = listNode.next;
}
```

- 链表需要熟悉其常用操作方式，特别是其前驱指针以及后继指针的操作。目前还不太熟练。

